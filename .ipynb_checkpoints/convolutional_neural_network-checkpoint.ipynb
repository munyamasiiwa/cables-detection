{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MJ5F2JjE8V9J"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, MaxPool2D\n",
        "from tensorflow.keras.layers import Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ud4pEjvt8V9N"
      },
      "outputs": [],
      "source": [
        "# Clear previous TensorFlow session\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Initialize the CNN\n",
        "cnn = Sequential([\n",
        "    # Step 1 - Convolutional Layer\n",
        "    Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=(64, 64, 3)),\n",
        "    # Step 2 - Pooling Layer\n",
        "    MaxPooling2D(pool_size=2, strides=2),\n",
        "    # Adding a second convolutional layer\n",
        "    Conv2D(filters=32, kernel_size=3, activation='relu'),\n",
        "    MaxPooling2D(pool_size=2, strides=2),\n",
        "    # Step 3 - Flattening Layer\n",
        "    Flatten(),\n",
        "    # Step 4 - Full Connection Layer\n",
        "    Dense(units=128, activation='relu'),\n",
        "    Dropout(0.5),  # Dropout layer to reduce overfitting\n",
        "    # Step 5 - Output Layer\n",
        "    Dense(units=1, activation='sigmoid')\n",
        "\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=4096,activation=\"relu\"))\n",
        "model.add(Dense(units=4096,activation=\"relu\"))\n",
        "model.add(Dense(units=1, activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "K-EzzFtF4mqi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Compile the CNN\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWJyCuea5L4i",
        "outputId": "6400d134-1794-409d-f8ee-3e43c36cc1f6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 112, 112, 64)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 56, 56, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 28, 28, 256)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 14, 14, 512)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 7, 7, 512)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4096)              102764544 \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 4097      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 134264641 (512.18 MB)\n",
            "Trainable params: 134264641 (512.18 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbdilwWG8V9P"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Compile the CNN\n",
        "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "cnn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "AXF-Iuic83dr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77j5sDpW8V9R",
        "outputId": "3541615b-2e09-49a4-f90e-c9dcb07905d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 482 images belonging to 2 classes.\n",
            "Found 482 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# Load training and test data using ImageDataGenerator\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator( rescale=1./255,\n",
        "    rotation_range=40,  # Random rotations between 0-40 degrees\n",
        "    width_shift_range=0.2,  # Random horizontal shifts\n",
        "    height_shift_range=0.2,  # Random vertical shifts\n",
        "    shear_range=0.2,  # Shearing\n",
        "    zoom_range=0.2,  # Random zoom\n",
        "    horizontal_flip=True,  # Random horizontal flips\n",
        "    fill_mode='nearest'  # Strategy for filling in newly created pixels\n",
        "\n",
        "                                                                 )\n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator( rescale=1./255,\n",
        "    rotation_range=40,  # Random rotations between 0-40 degrees\n",
        "    width_shift_range=0.2,  # Random horizontal shifts\n",
        "    height_shift_range=0.2,  # Random vertical shifts\n",
        "    shear_range=0.2,  # Shearing\n",
        "    zoom_range=0.2,  # Random zoom\n",
        "    horizontal_flip=True,  # Random horizontal flips\n",
        "    fill_mode='nearest'  # Strategy for filling in newly created pixels\n",
        "                                                              )\n",
        "\n",
        "training_set = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/dataset/training_set',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/dataset/test_set',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training and test data using ImageDataGenerator\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator( rescale=1./255,\n",
        "    rotation_range=40,  # Random rotations between 0-40 degrees\n",
        "    width_shift_range=0.2,  # Random horizontal shifts\n",
        "    height_shift_range=0.2,  # Random vertical shifts\n",
        "    shear_range=0.2,  # Shearing\n",
        "    zoom_range=0.2,  # Random zoom\n",
        "    horizontal_flip=True,  # Random horizontal flips\n",
        "    fill_mode='nearest'  # Strategy for filling in newly created pixels\n",
        "\n",
        "                                                                 )\n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator( rescale=1./255,\n",
        "    rotation_range=40,  # Random rotations between 0-40 degrees\n",
        "    width_shift_range=0.2,  # Random horizontal shifts\n",
        "    height_shift_range=0.2,  # Random vertical shifts\n",
        "    shear_range=0.2,  # Shearing\n",
        "    zoom_range=0.2,  # Random zoom\n",
        "    horizontal_flip=True,  # Random horizontal flips\n",
        "    fill_mode='nearest'  # Strategy for filling in newly created pixels\n",
        "                                                              )\n",
        "\n",
        "training_set = train_datagen.flow_from_directory(\n",
        "    'training_set',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "    'test_set',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary')\n"
      ],
      "metadata": {
        "id": "Fb_TJP2V9zv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcLbdOhL8V9S"
      },
      "outputs": [],
      "source": [
        "# Train the CNN on the Training set and evaluate it on the Test set\n",
        "history = cnn.fit(\n",
        "    x=training_set,\n",
        "    validation_data=test_set,\n",
        "    epochs=25)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the CNN on the Training set and evaluate it on the Test set\n",
        "history = model.fit(\n",
        "    x=training_set,\n",
        "    validation_data=test_set,\n",
        "    epochs=25)"
      ],
      "metadata": {
        "id": "LwhxEim59g0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "ABvON-fq8V9T",
        "outputId": "546d1d84-36b4-4b92-b87b-b5d2bb245079"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 33ms/step\n",
            "WELL INSULATED CABLE\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Making a single prediction\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "test_image_path = ('/content/drive/MyDrive/dataset/predict/DEFECTIVE/DAMAGED9.jpg')\n",
        "test_image = image.load_img(test_image_path, target_size=(64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis=0)\n",
        "#test_image = test_image / 255.0  # Rescale the same as training data\n",
        "result = cnn.predict(test_image)\n",
        "if result[0][0] >= 0.8:\n",
        "    prediction = 'WELL INSULATED CABLE'\n",
        "else:\n",
        "    prediction = 'DEFECTIVE CABLE(DAMAGED)'\n",
        "\n",
        "print(prediction)\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(test_image[0].astype(np.uint8))\n",
        "plt.title('Prediction: ' + prediction)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNzZpWV68V9U"
      },
      "outputs": [],
      "source": [
        "cnn.save('/content/drive/MyDrive/dataset/model')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVI3XRgq8V9V",
        "outputId": "b6242269-25b2-4ebe-bfbe-bae921fe000c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "cnn.save('/content/drive/MyDrive/dataset/model/cables.h5', save_format='h5')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}